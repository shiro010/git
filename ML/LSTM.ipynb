{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e68a45a",
   "metadata": {},
   "source": [
    "エラー対処前"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb58e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a219b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 82\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(length_of_sequences \u001b[38;5;241m-\u001b[39m maxlen):\n\u001b[1;32m     81\u001b[0m     x\u001b[38;5;241m.\u001b[39mappend(x[i:i\u001b[38;5;241m+\u001b[39mmaxlen])\n\u001b[0;32m---> 82\u001b[0m     t\u001b[38;5;241m.\u001b[39mappend(\u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mmaxlen\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     84\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, maxlen, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     85\u001b[0m t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(t)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "class  EarlyStopping:\n",
    "    def __init__(self, patience=5, verbose=False, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = - val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping Counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "    \n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.best_score:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.LSTM(1, hidden_dim,batch_first=True)\n",
    "        self.l2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        nn.init.xavier_normal_(self.l1.weight_ih_l0)\n",
    "        nn.init.orthogonal_(self.l1.weight_hh_l0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, _ = self.l1(x)\n",
    "        y = self.l2(h[:,-1])\n",
    "        return y\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    np.random.seed(124)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    def mask(T=200):\n",
    "        mask = np.zeros(T)\n",
    "        indices = np.random.permutation(np.arange(T))[:2]\n",
    "        mask[indices] = 1\n",
    "        return mask\n",
    "    \n",
    "    def toy_problem(N=10000, T=200):\n",
    "        signals = np.random.uniform(low=0.0, high=1.0, size=(N, T))\n",
    "        masks = np.zeros((N,T))\n",
    "        for i in range(N):\n",
    "            masks[i] = mask(T)\n",
    "        \n",
    "        data = np.zeros((N, T, 2))\n",
    "        data[:, :, 0] = signals[:]\n",
    "        data[:, :, 1] = masks[:]\n",
    "        target = (signals * masks).sum(axis=1).reshape(N, 1)\n",
    "        return (data, target)\n",
    "    \n",
    "    N = 10000\n",
    "    T = 200\n",
    "    maxlen = T\n",
    "    x, t  = toy_problem(T)\n",
    "    length_of_sequences = N\n",
    "\n",
    "    maxlen = 25\n",
    "\n",
    "    x=[]\n",
    "    t=[]\n",
    "\n",
    "    for i in range(length_of_sequences - maxlen):\n",
    "        x.append(x[i:i+maxlen])\n",
    "        t.append(t[i+maxlen])\n",
    "\n",
    "    x = np.array(x).reshape(-1, maxlen, 1)\n",
    "    t = np.array(t).reshape(-1, 1)\n",
    "\n",
    "    x_train, x_val, t_train, t_val = train_test_split(x, t, test_size=0.2, shuffle=False)\n",
    "\n",
    "    model = LSTM(50).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss(reduction=\"mean\")\n",
    "    optimizer = optimizers.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.009), amsgrad=True)\n",
    "\n",
    "    def compute_loss(t, y):\n",
    "        return criterion(y, t)\n",
    "    \n",
    "    def train_step(x, t):\n",
    "        x = torch.Tensor(x).to(device)\n",
    "        t = torch.Tensor(t).to(device)\n",
    "        model.train()\n",
    "        preds = model(x)\n",
    "        loss = compute_loss(t, preds)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return loss, preds\n",
    "    \n",
    "    def val_step(x, t):\n",
    "        x = torch.Tensor(x).to(device)\n",
    "        t = torch.Tensor(t).to(device)\n",
    "        model.eval()\n",
    "        preds = model(x)\n",
    "        loss = criterion(preds, t)\n",
    "        return loss, preds\n",
    "    \n",
    "    epochs = 1000\n",
    "    batch_size = 100\n",
    "\n",
    "    n_batches_train = x_train.shape[0] // batch_size + 1\n",
    "    n_batches_val = x_val.shape[0] // batch_size + 1\n",
    "\n",
    "    hist = {\"loss\":[], \"val\":[]}\n",
    "    es = EarlyStopping(patience=10, verbose=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0.\n",
    "        val_loss = 0.\n",
    "        x_, t_ = shuffle(x_train, t_train)\n",
    "\n",
    "        for batch in range(n_batches_train):\n",
    "            start = batch * batch_size\n",
    "            end = start + batch_size\n",
    "            loss, _ = train_step(x_[start:end], t_[start:end])\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        for batch in range(n_batches_val):\n",
    "            start = batch * batch_size\n",
    "            end = start + batch_size\n",
    "            loss, _ = val_step(x_val[start:end], t_val[start:end])\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        train_loss /= n_batches_train\n",
    "        val_loss /= n_batches_val\n",
    "\n",
    "        hist[\"loss\"].append(train_loss)\n",
    "        hist[\"val\"].append(val_loss)\n",
    "\n",
    "        print(\"epoch:{}, loss:{:.3f}, val_loss{:.3f}\".format(epoch+1, train_loss, val_loss))\n",
    "        \n",
    "        if es(val_loss, model):\n",
    "            break\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    gen = [None for i in range(maxlen)]\n",
    "\n",
    "    z = x[:1]\n",
    "\n",
    "    for i in range(length_of_sequences - maxlen):\n",
    "        z_ = torch.Tensor(z[-1:]).to(device)\n",
    "        preds = model(z_).data.cpu().numpy()\n",
    "        z = np.append(z, preds)[1:]\n",
    "        z = z.reshape(-1, maxlen, 1)\n",
    "        gen.append(preds[0, 0])\n",
    "\n",
    "    # 予測値を可視化\n",
    "    fig = plt.figure()\n",
    "    plt.rc(\"font\", family=\"serif\")\n",
    "    plt.xlim([0, 2*T])\n",
    "    plt.ylim([-1.5, 1.5])\n",
    "    plt.plot(N, x, color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
    "    plt.plot(N, gen, color=\"black\", linewidth=1, marker=\"o\", markersize=1, markerfacecolor=\"black\", markeredgecolor=\"black\")\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workspace-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
