{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "081b7074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pathlib\n",
    "import re\n",
    "import janome\n",
    "import jaconv\n",
    "\n",
    "# dicというディレクトリにダウンロードしてきた極性辞書を入れておく\n",
    "p_dic = pathlib.Path('dic')\n",
    "\n",
    "# 極性辞書はテキスト形式でダウンロードしてきている想定\n",
    "for i in p_dic.glob('*.dic'):\n",
    "    with open (i, 'r', encoding = 'cp932') as f:\n",
    "        #単語・読み仮名・品詞・スコアに分割してリストとして格納\n",
    "        x = [ii.replace('\\n', '').split(':') for ii in  f.readlines()]\n",
    "\n",
    "posi_nega_df = pd.DataFrame(x, columns = ['基本形', '読み', '品詞', 'スコア'])\n",
    "# jaconvを使って読み仮名を全てカタカナに変換\n",
    "posi_nega_df['読み'] = posi_nega_df['読み'].apply(lambda x : jaconv.hira2kata(x))\n",
    "# なぜか読みや品詞まで同じなのに、異なるスコアが割り当てられていたものがあったので重複を削除\n",
    "posi_nega_df = posi_nega_df[~posi_nega_df[['基本形', '読み', '品詞']].duplicated()]\n",
    "# print(posi_nega_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d8225b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_temp = pathlib.Path('text')\n",
    "\n",
    "article_list = []\n",
    "\n",
    "# フォルダ内のテキストファイルを全てサーチ\n",
    "for p in p_temp.glob('**/*.txt'):\n",
    "    #第二階層フォルダ名がニュースサイトの名前になっているので、それを取得\n",
    "    media = p.parent.name\n",
    "    file_name = p.name\n",
    "    # print(file_name)\n",
    "\n",
    "    if file_name != 'LICENSE.txt' and file_name != 'CHANGES.txt' and file_name != 'README.txt':\n",
    "        #テキストファイルを読み込む\n",
    "        with open(p, 'r') as f:\n",
    "            #テキストファイルの中身を一行ずつ読み込み、リスト形式で格納\n",
    "            article = f.readlines()\n",
    "            #不要な改行等を置換処理\n",
    "            article = [re.sub(r'[\\n \\u3000]', '', i) for i in article]\n",
    "    #ニュースサイト名・記事URL・日付・記事タイトル・本文の並びでリスト化\n",
    "            article_list.append([media, article[0], article[1], article[2], ''.join(article[3:])])\n",
    "    else :\n",
    "        continue\n",
    "\n",
    "\n",
    "article_df = pd.DataFrame(article_list)\n",
    "\n",
    "# article_df.head()\n",
    "# print(article_df.shape) #(7376, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5161276",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = article_df\n",
    "# print(news_df)\n",
    "\n",
    "from janome.tokenizer import Tokenizer\n",
    "from janome.analyzer import Analyzer\n",
    "from janome.charfilter import *\n",
    "\n",
    "t = Tokenizer()\n",
    "char_filters = [UnicodeNormalizeCharFilter()]\n",
    "analyzer = Analyzer(char_filters=char_filters, tokenizer=t)\n",
    "\n",
    "word_lists = []\n",
    "for i, row in news_df.iterrows(): \n",
    "    # print(i) \n",
    "    # print(row[3])  \n",
    "    # print(row[4])\n",
    "    row_lists = []\n",
    "    for t in analyzer.analyze(row[4]):\n",
    "        #形態素\n",
    "        surf = t.surface\n",
    "        #基本形\n",
    "        # base = t.base_form\n",
    "        #品詞\n",
    "        # pos = t.part_of_speech\n",
    "        #読み\n",
    "        # reading = t.reading\n",
    "        \n",
    "        row_lists.append(t)\n",
    "    word_lists.append(row_lists)\n",
    "\n",
    "\n",
    "# word_df = pd.DataFrame(word_lists, columns=['ニュース'])\n",
    "\n",
    "# word_df = pd.DataFrame(word_lists, columns = ['ニュースNo.', '単語', '基本形', '品詞', '読み'])\n",
    "# word_df['品詞'] = word_df['品詞'].apply(lambda x : x.split(',')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f411bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_list = []\n",
    "for i in range(len(word_lists)):\n",
    "    surface_words = [token.surface for token in word_lists[i]]\n",
    "    joined = ' '.join(surface_words)\n",
    "    article_list.append(joined)\n",
    "\n",
    "df = pd.DataFrame(article_list, columns=[\"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc172cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>もうすぐ ジューン ・ ブライド と 呼ば れる 6 月 。 独 女 の 中 に は 自分 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>携帯 電話 が 普及 する 以前 、 恋人 へ の 連絡 ツール は 一般 電話 が 普通 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>「 男性 は やっぱり 、 女性 の “ すっぴん ” が 大好き な ん です か ね 」...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ヒップ の 加 齢 による 変化 は 「 たわむ → 下がる → 内 に 流れる 」 、 バ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6 月 から 支給 さ れる 子ども 手当 だ が 、 当初 は 子ども 一 人 当たり 月...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article\n",
       "0  もうすぐ ジューン ・ ブライド と 呼ば れる 6 月 。 独 女 の 中 に は 自分 ...\n",
       "1  携帯 電話 が 普及 する 以前 、 恋人 へ の 連絡 ツール は 一般 電話 が 普通 ...\n",
       "2  「 男性 は やっぱり 、 女性 の “ すっぴん ” が 大好き な ん です か ね 」...\n",
       "3  ヒップ の 加 齢 による 変化 は 「 たわむ → 下がる → 内 に 流れる 」 、 バ...\n",
       "4  6 月 から 支給 さ れる 子ども 手当 だ が 、 当初 は 子ども 一 人 当たり 月..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77f42d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('token.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_6322041",
   "language": "python",
   "name": "virtual_6322041"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
