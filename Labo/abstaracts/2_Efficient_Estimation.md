# TAMMICフォーマット
## Title
Efficient Estimation of Word Representations in
Vector Space  

[Submitted on 16 Jan 2013 (v1), last revised 7 Sep 2013 (this version, v3)]
## Author
Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean

## Motivation
精度も良く、単語ベクトルで足し引きできるような線形性を持つような単語ベクトルを作成するモデルを作成したい。

## Method
NNLM(neural network language model)を拡張してつくるよー
## Insight
順伝播とreccurent neural networkと比べても簡単なモデルで高いクオリティーのモデルできたよ（CBOW, skip-gram）<br>
簡単な構成だから大きなデータセットを用いて精度の良い大きなベクトル空間ができた。
最近いろいろneural networkをNLPに使われているからこのモデルは使えそう。
## Contribution Summary

# KURRフォーマット
## keyword  
- word representation models
  - LSA(Latent Semantic Analysis)
  - LDA(Latent Dirichlet Analysis)


## Unknown

## Reflection

## Reference