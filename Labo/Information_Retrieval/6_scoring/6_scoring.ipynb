{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9767027",
   "metadata": {},
   "source": [
    "https://nlp.stanford.edu/IR-book/pdf/06vect.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e65598d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<script type=\"text/javascript\" async src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js\">\n",
    "</script>\n",
    "<script type=\"text/x-mathjax-config\">\n",
    " MathJax.Hub.Config({\n",
    " tex2jax: {\n",
    " inlineMath: [['$', '$'] ],\n",
    " displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
    " }\n",
    " });\n",
    "</script>\n",
    "## 6.1：重み付きゾーンスコアリングとその最適化\n",
    "\n",
    "---\n",
    "\n",
    "### 🔸 重み付きゾーンスコアリング（Weighted Zone Scoring）\n",
    "\n",
    "- 文書には複数の **ゾーン**（例：author, title, body）があり、各ゾーンごとにクエリが一致しているかをブール値（$1$ or $0$）で評価する。\n",
    "- 各ゾーンには重み $g_i ∈ [0, 1]$ を割り当て、文書のスコアは以下の線形結合で与えられる：\n",
    "\n",
    "  $\n",
    "  score(q, d) = Σ g_i * s_i\n",
    "  $\n",
    "\n",
    "  - $s_i$：ゾーン $i$ にクエリが一致しているか（0 または 1）\n",
    "  - $g_i$：ゾーン $i$ の重み（全ゾーンの重みは合計で1）\n",
    "\n",
    "- **例**：  \n",
    "  クエリ shakespeare に対して：\n",
    "  - author に一致 → 0.2\n",
    "  - title に一致 → 0.3\n",
    "  - body に一致 → 0.5  \n",
    "  → title と body に一致する文書のスコアは $0.3 + 0.5 = 0.8$\n",
    "\n",
    "- インデックスを活用した高速なスコア計算アルゴリズム（ZONESCORE）も紹介されている。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔸 重みの学習（Learning Weights）\n",
    "\n",
    "- 各ゾーンの重み $g_i$ は専門家による設定も可能だが、通常は**機械学習によって自動で学習される**。\n",
    "- 学習には、以下のようなトレーニングデータが使われる：\n",
    "\n",
    "  $\n",
    "  Φ_j = (d_j, q_j, r(d_j, q_j))\n",
    "  $\n",
    "\n",
    "  - $d_j$：文書、$q_j$：クエリ、$r(d_j, q_j)$：関連性（Relevant / Non-relevant）\n",
    "\n",
    "- 2ゾーン（タイトルと本文）でのスコア関数の例：\n",
    "\n",
    "  $\n",
    "  score(d, q) = g * s_T(d, q) + (1 - g) * s_B(d, q)\n",
    "  $\n",
    "\n",
    "- 各 $(d_j, q_j)$ に対してスコアと実際の関連性を比較し、**誤差（2乗誤差）を最小化**することで $g$ を学習する。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔸 最適重み g の導出（The Optimal Weight g）\n",
    "\n",
    "- 4つのパターンでトレーニングデータを分類：\n",
    "  - $s_T=1, s_B=0$（タイトル一致のみ）\n",
    "  - $s_T=0, s_B=1$（本文一致のみ）\n",
    "  - $s_T=0, s_B=0$（一致なし）\n",
    "  - $s_T=1, s_B=1$（両方一致）\n",
    "\n",
    "- 各パターンの中で Relevant / Non-relevant の数を数える：\n",
    "  - $n_{10r}$：タイトル一致のみでRelevant\n",
    "  - $n_{01n}$：本文一致のみでNon-relevant\n",
    "  - など\n",
    "\n",
    "- 最適な重み $g$ は以下で計算される：\n",
    "\n",
    "  $\n",
    "  g = (n_{10r} + n_{01n}) / (n_{10r} + n_{10n} + n_{01r} + n_{01n})\n",
    "  $\n",
    "\n",
    "- これは、トレーニングデータの誤差を最小にする $g$ を解析的に導出した式。(ゾーンが2つだからできた？)\n",
    "\n",
    "---\n",
    "\n",
    "このアプローチは、簡単なブール一致と線形スコアに基づくランキングモデルであり、**機械学習による情報検索の基礎**とも言える構成です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026e7c9f",
   "metadata": {},
   "source": [
    "## 6.2 語の頻度と重み付け（Term Frequency and Weighting）\n",
    "\n",
    "### 🔸 背景と目的\n",
    "\n",
    "- これまでは「語が出現するかどうか（0 または 1）」だけでスコアを決めていた。\n",
    "- 次のステップは、「語が何回現れるか」を使ってスコアに差をつけること。\n",
    "- 特に自由形式のクエリ（free text query）では、語の出現回数は関連性に大きく関わる。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔸 Term Frequency（TF：語の出現回数）\n",
    "\n",
    "- 各語 $t$ が文書 $d$ に何回登場したかをカウントする。\n",
    "\n",
    "  $\n",
    "  tf_{t,d} = 文書 d における語 t の出現回数\n",
    "  $\n",
    "\n",
    "- 「Bag of Words（単語の袋）」モデルに基づく。\n",
    "  - 単語の順番は無視し、出現回数のみを考慮する。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔸 Inverse Document Frequency（IDF：逆文書頻度）\n",
    "\n",
    "- 出現頻度の高い語（例：the, is）は重要度が低くなるように重みを調整する。\n",
    "- 定義：\n",
    "\n",
    "  $\n",
    "  idf_t = log(N / df_t)\n",
    "  $\n",
    "\n",
    "  - $N$：全文書数\n",
    "  - $df_t$：語 $t$ が出現する文書の数（document frequency）\n",
    "\n",
    "- **珍しい語ほど IDF が高く、よくある語は IDF が低い。**\n",
    "\n",
    "---\n",
    "\n",
    "### 🔸 TF-IDF（語の重みの組み合わせ）\n",
    "\n",
    "- TF と IDF を掛け合わせた代表的なスコア：\n",
    "\n",
    "  $\n",
    "  \\textrm{tf-idf}_{t,d} = tf_{t,d} × idf_t\n",
    "  $\n",
    "\n",
    "- 特徴：\n",
    "  1. 限られた文書に頻出 → 高スコア（高い識別力）\n",
    "  2. 多くの文書に登場 → 低スコア（識別力が低い）\n",
    "  3. 全文書に登場 → 最小スコア（意味がない）\n",
    "\n",
    "---\n",
    "\n",
    "### 🔸 文書スコアの計算（Overlap Score）\n",
    "\n",
    "- クエリ中のすべての語に対し、文書中の TF-IDF を合計する：\n",
    "\n",
    "  $\n",
    "  Score(q, d) = Σ_{t∈q} tf-idf_{t,d}\n",
    "  $\n",
    "\n",
    "- より厳密なスコアリング手法は、次のセクション（6.3）でベクトル空間モデルとして説明される。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb59f0a",
   "metadata": {},
   "source": [
    "## 6.3 ベクトル空間モデルによるスコアリング（The Vector Space Model for Scoring）\n",
    "\n",
    "### 🔸 概要\n",
    "\n",
    "- 文書やクエリを「語の重みベクトル」として表現し、**数値的な類似度スコア**を用いてランキングを行う。\n",
    "- 中心的な手法は **コサイン類似度（cosine similarity）** に基づく。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔸 6.3.1 ドット積（Dot Products）\n",
    "\n",
    "- 文書 $d$ は語彙に基づいたベクトル $V(d)$ として表現される（通常は TF-IDF を重みとして使用）。\n",
    "- 文書同士の類似度は以下の式で定義される：\n",
    "\n",
    "  $\n",
    "  sim(d1, d2) = \\frac{V(d1) · V(d2)}{|V(d1)| × |V(d2)|}\n",
    "  $\n",
    "\n",
    "  - 分子：ドット積（同じ語の重みの積の総和）\n",
    "  - 分母：ユークリッド長（ベクトルの大きさ）の積（＝正規化）\n",
    "\n",
    "- この手法により、文書の長さに依存せず、**内容的な近さ**だけを比較できる。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔸 6.3.2 クエリをベクトルとして扱う（Queries as Vectors）\n",
    "\n",
    "- クエリも語の重みベクトル $V(q)$ として扱うことで、文書と同様にスコア計算が可能。\n",
    "\n",
    "  $\n",
    "  score(q, d) = \\frac{V(q) · V(d)}{|V(q)| × |V(d)|}\n",
    "  $\n",
    "\n",
    "- クエリと文書の類似度スコアが高いほど、文書のランキングが上がる。\n",
    "\n",
    "- 例：  \n",
    "  クエリ jealous gossip → ベクトル $(0, 0.707, 0.707)$  (affection, jealous, gossip)に相当、単位ベクトル化されている  \n",
    "  このベクトルと各文書ベクトルの内積（コサイン類似度）を取ることでランキングを得る。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔸 6.3.3 ベクトルスコアの計算（Computing Vector Scores）\n",
    "\n",
    "- term-at-a-time（語ごとにスコアを加算）で各文書のスコアを累積計算。\n",
    "- 各文書に対してスコアを格納する配列 $Scores[]$ を使い、クエリ内の全語について加算していく。\n",
    "\n",
    "- アルゴリズムの概要：\n",
    "\n",
    "  1. クエリ内の各語について重みを計算（例：IDF）\n",
    "  2. その語が含まれる文書ごとに $Scores[doc] $+=$ \\textrm{tf-idf} × idf$\n",
    "  3. 最終的に正規化（文書ベクトルの長さで割る）\n",
    "  4. スコア上位の文書を $Top K$ として返す\n",
    "\n",
    "- **累積配列（accumulator）** により効率的にスコアを管理可能。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔸 ベクトル空間モデルの利点\n",
    "\n",
    "- 文書とクエリを同一の数値ベクトル空間で扱えるため、定量的かつ高速な比較が可能。\n",
    "- 検索クエリだけでなく、「この文書に似た他の文書を探す」といった**類似文書検索**にも応用できる。\n",
    "- TF-IDFやコサイン類似度に基づいた**実用的かつ直感的なスコアリング方式**。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
